{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "<h1>Object Detection</h1>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h3>Things you will learn</h3>\n<ul>\n    <li>Skin Detection</li>\n    <li>Contours</li>\n    <li>Canny edge detection</li>\n</ul>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<p>1. Skin Contour</p>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport cv2 # the usual\nimport matplotlib.pyplot as plt",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Lets read in our pic first\nimage = cv2.imread('faces.jpeg',1)\n# HSV is closer to how humans perceive color\nb,g,r = cv2.split(image)\nhsv = cv2.cvtColor(cv2.merge([r,g,b]), cv2.COLOR_RGB2HSV)\n\n# now lets get the multiple channels \nh = hsv[:,:,0]\ns = hsv[:,:,1]\nv = hsv[:,:,2]\n\n# Now lets get the channels side by side\nhsvSplit = np.concatenate((h,s,v), axis=1)\nplt.imshow(hsvSplit,cmap=plt.get_cmap('gray'))\n# Set to gray or it wont look correct\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<p>Now we will apply a filter on our saturation channel</p>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ret, minSat = cv2.threshold(s,40,255, cv2.THRESH_BINARY)\nplt.imshow(minSat,cmap='gray')\n# Set to gray or it wont look correct\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<p>Now we will apply a filter on our hue channel</p>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ret, maxHue = cv2.threshold(h,15, 255, cv2.THRESH_BINARY_INV)\nplt.imshow(maxHue, cmap='gray')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "final = cv2.bitwise_and(minSat,maxHue) # Final image combines both \nplt.imshow(final, cmap='gray')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "plt.imshow(cv2.merge([r,g,b]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h3>2. Contours</h3>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Lets read in our image \nimage = cv2.imread('detect_blob.png',1)\ngray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\nthresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 115, 1)\nplt.imshow(thresh,cmap='gray')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<p>Now lets formulate our contours command</p>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# hierarchy is the parent child relationship of all the contours\ncontours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\nimage2 = image.copy()\nindex = -1\nthickness = 4\ncolor = (255,0,255) # Color channel for contour\n\ncv2.drawContours(image2, contours, index, color, thickness)\nplt.imshow(image2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<p>Note: At this stage we arent done, now we need to extrapolate information about each of these objects and apply more filtering</p>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<p>2.2 Area, perimeter, center, and curvature</p>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<p>Now that we finished contouring our objects on the image, let us keep going and extract more information about these objects</p>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "objects = np.zeros([image.shape[0], image.shape[1],3],'uint8')\n\n# lets loop over our contours\nfor c in contours:\n    cv2.drawContours(objects, [c], -1, color, -1)\n    #object matrix, enclose value of c in list\n    #-1 means all contours, and -1 means fill in all colors\n    \n    area = cv2.contourArea(c)\n    perimeter = cv2.arcLength(c, True)\n    \n    # Centroid of contour\n    M = cv2.moments(c) # called image moment\n    cx = int(M['m10']/M['m00'])\n    cy = int(M['m01']/M['m00'])\n    cv2.circle(objects, (cx,cy),4,(0,0,255),-1)\n    print(\"Area: {}, perimeter: {}\".format(area,perimeter))\n    \nplt.imshow(objects)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h3>3. Canny edge detection </h3>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<p>Edge detection algorithm that works pretty well to detect color changes in the image</p>\n<p>This also draws lines around what is thinks are edges</p>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "image = cv2.imread(\"tomatoes.jpg\",1)\nplt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nhsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n# Get our threshold\nres,thresh = cv2.threshold(hsv[:,:,0], 25, 255, cv2.THRESH_BINARY_INV)\nplt.imshow(thresh,cmap='gray')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "edges = cv2.Canny(image, 100, 70) # Pass in original image\n# Two other params are lower and upper threshold limits of edges\nplt.imshow(edges,cmap='gray')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<p>Challange: For all objects in the image, segment them out, draw them on a blank image, and print the perimeter and area</p>\n<p>Only draw large objects (area of greater than 1000 px).\n    Each object should be drawn with its own color</p>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "img = cv2.imread(\"fuzzy.png\",1) #Starter code\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Solution \n# First \nimport random\nb,g,r = cv2.split(img)\nimg = cv2.merge([r,g,b])\n\ngray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\nblur = cv2.GaussianBlur(gray, (3,3),0)\n\nthresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 205, 1)\nplt.imshow(thresh,cmap='gray')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Rest of code\n\ncontours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\nprint(len(contours))\n\nfiltered = []\nfor c in contours:\n    if cv2.contourArea(c) < 1000:continue\n    filtered.append(c)\n\nprint(len(filtered))\n\nobjects = np.zeros([img.shape[0],img.shape[1],3], 'uint8')\nfor c in filtered:\n    col = (random.randint(0,255), random.randint(0,255), random.randint(0,255))\n    cv2.drawContours(objects,[c], -1, col, -1)\n    area = cv2.contourArea(c)\n    p = cv2.arcLength(c,True)\n    print(area,p)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "plt.imshow(objects)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}